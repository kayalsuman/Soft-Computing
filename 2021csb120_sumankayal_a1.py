# -*- coding: utf-8 -*-
"""2021CSB120_SumanKayal_A1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B9KVKONUT6qbfwtJURgLfv5bMldfTIug

SUMAN KAYAL

2021CSB120

SOFT COMPUTING ASSIGNMENT-1
"""

import pandas as pd
with open('iris.data','r') as file:
  csv_reader=pd.read_csv(file)

df=pd.read_csv('/content/iris.data')

print(df)

from google.colab import drive
drive.mount('/content/drive')

resulted_data=df.drop(['Iris-setosa'],axis=1)
print(resulted_data)

import numpy as np

def min_max_normalization_2d(resulted_data):
  min_vals=np.min(resulted_data,axis=0)
  max_vals=np.max(resulted_data,axis=0)


  normalized_matrix=(resulted_data-min_vals)/(max_vals-min_vals)

  return normalized_matrix

normalized_matrix=min_max_normalization_2d(resulted_data)
print(normalized_matrix)

import numpy as np

#  'similarity_matrix' contains the m x m similarity matrix


# Function to find the average dissimilarity and form a cluster
def form_cluster(similarity_matrix):
    m = similarity_matrix.shape[0]
    clusters = []

    for i in range(m):
        # Calculate average dissimilarity of i-th object with others
        avg_dissimilarity = np.sum(similarity_matrix[i]) / (m - 1)

        # Form a cluster Ci with i-th object and objects having dissimilarity less than average
        cluster = [j for j in range(m) if j != i and similarity_matrix[i, j] < avg_dissimilarity]
        cluster.append(i)  # Include the i-th object in the cluster
        clusters.append(cluster)

    return clusters

# Call the function to form clusters
clusters = form_cluster(similarity_matrix)

# 'clusters' is a list of lists, where each inner list represents a cluster
print(clusters)

import numpy as np

#  'df' contains the normalized dataset (m x n matrix)


# Function to calculate Euclidean distance between two objects
def euclidean_distance(x, y):
    return np.sqrt(np.sum((x - y) ** 2))

# Function to compute the similarity matrix
def create_similarity_matrix(data):
    m, n = data.shape
    similarity_matrix = np.zeros((m, m))

    for i in range(m):
        for j in range(m):
            similarity_matrix[i, j] = euclidean_distance(data.iloc[i], data.iloc[j])


    return similarity_matrix

# Call the function to create the similarity matrix
similarity_matrix = create_similarity_matrix(normalized_matrix)

# 'similarity_matrix' is the m x m similarity matrix based on Euclidean distance
print(similarity_matrix)

#  'clusters' contains the list of clusters obtained from the previous step

# Function to remove subsets from the list of clusters
def remove_subsets(clusters):
    p = len(clusters)
    subset_flags = [False] * p

    for i in range(p):
        for j in range(p):
            if i != j and set(clusters[i]).issubset(set(clusters[j])):
                subset_flags[i] = True
                break

    pruned_clusters = [cluster for i, cluster in enumerate(clusters) if not subset_flags[i]]
    return pruned_clusters

# Call the function to remove subsets from the list of clusters
pruned_clusters = remove_subsets(clusters)

# 'pruned_clusters' contains p (< m) clusters after removing any subsets
print(pruned_clusters)

#  'pruned_clusters' contains the list of pruned clusters obtained from the previous step

# Function to compute the similarity between two clusters
def compute_similarity(cluster1, cluster2):
    intersection = len(set(cluster1) & set(cluster2))
    union = len(set(cluster1) | set(cluster2))
    similarity = intersection / union
    return similarity

# Function to create the similarity matrix C
def create_similarity_matrix_p(pruned_clusters):
    p = len(pruned_clusters)
    similarity_matrix_p = np.zeros((p, p))

    for i in range(p):
        for j in range(p):
            similarity_matrix_p[i, j] = compute_similarity(pruned_clusters[i], pruned_clusters[j])

    return similarity_matrix_p

# Call the function to create the similarity matrix C
similarity_matrix_p = create_similarity_matrix_p(pruned_clusters)

# 'similarity_matrix_p' is the p x p similarity matrix between clusters
print(similarity_matrix_p)

# Function to find the most similar clusters and merge them
def merge_most_similar_clusters(similarity_matrix_p, pruned_clusters):
    p = len(pruned_clusters)
    max_similarity = -1.0
    most_similar_clusters = (None, None)

    # Find the most similar clusters Ck and Cl
    for k in range(p):
        for l in range(k + 1, p):  # To avoid checking pairs twice (symmetric matrix)
            similarity = similarity_matrix_p[k, l]
            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_clusters = (k, l)

    # Get the indices of the most similar clusters
    k, l = most_similar_clusters

    # Merge the most similar clusters Ck and Cl to get a new cluster Ckl
    Ck = set(pruned_clusters[k])
    Cl = set(pruned_clusters[l])
    Ckl = list(Ck.union(Cl))

    # Remove the individual clusters Ck and Cl from the list and add the new cluster Ckl
    pruned_clusters.pop(max(k, l))
    pruned_clusters.pop(min(k, l))
    pruned_clusters.append(Ckl)

    return pruned_clusters

# Call the function to find the most similar clusters and merge them
merged_clusters = merge_most_similar_clusters(similarity_matrix_p, pruned_clusters)

# 'merged_clusters' contains the updated list of clusters after merging the most similar clusters
print(merged_clusters)

